# 4장_처리율 제한 장치의 설계

# Rate limiter (처리율 제한 장치)

- client/service가 보내는 트래픽의 처리율(rate)을 제한하기 위한 장치
    - ex) HTTP 요청 횟수 제한, 3시간 동안 300개의 트윗만 올릴 수 있

API에 처리율 제한장치를 두면 좋은 점

- Dos 공격에 의한 resource starvation 방지
    - 정해진 요청 횟수를 초과하는 추가 요청에 대해서는 처리를 중단함으로써 Dos 공격 방지
- 비용 절감
    - 추가 요청에 대한 처리를 제한하면, 서버를 많이 두지 않아도 됌
    - 3rd party API에 횟수에 따른 사용료를 지불하는 경우, 횟수를 제한함으로써 비용 절감 가능
- 서버 과부하를 막음
    - bot에서 오는 트래픽/사용자의 잘못된 이용 패턴으로 유발된 트래픽을 걸러내는데 rate limiter사용 가능

# 처리율 제한장치 구현

## 1. 문제 이해 및 설계 범위 확정

면접관과 소통하면 어떤 제한 장치를 구현해야 하는지 분명히 할 수 있음

질문 예시

- 클라이언트 측 제한 장치, 서버 측 제한 장치 중 어떤 제한 장치를 구현해야 하는지
- 어떤 기준을 사용해서 API 호출을 제어해야 하는지 (ex. IP주소, 사용자 ID)
- 시스템 규모는 어느 정도여야 하는지
- 처리율 제한장치는 독립된 서비스인지, 애플리케이션 코드에 포함될 수 있는지

## 2. 개략적 설계안 제시 및 동의 구하기

클라이언트-서버 통신 모델 예시

### **처리율 제한 장치는 어디에 둘 것인가?**

- ~~클라이언트 측~~ : 클라이언트 요청은 쉽게 위변조가 가능해서 처리율 제한을 안정적으로 걸 수 없음
- 서버 측 : 처리율 제한 middleware가 API 서버로 가는 요청 통제
- gateway에 두기
    
    ![API 서버의 처리율이 초당 2개의 요청으로 제한된 상황에서, 3번째 요청을 같은 sec 안에 보내면 middleware가 클라이언트로 HTTP 상태코드 429 반환](https://prod-files-secure.s3.us-west-2.amazonaws.com/c572571b-8a19-4c28-929f-c23789a58601/402867e3-859e-47fe-a962-913d50bb7bce/Untitled.png)
    
    API 서버의 처리율이 초당 2개의 요청으로 제한된 상황에서, 3번째 요청을 같은 sec 안에 보내면 middleware가 클라이언트로 HTTP 상태코드 429 반환
    
    - 클라우드 마이크로서비스의 경우 API gateway 라는 컴포넌트에 처리율 제한 장치 구현
        
        `API gateway`
        
        - 처리율 제한, SSL termination, 사용자 authentication, IP whitelist 등을 지원하는 완전 위탁 관리형 서비스(fully manged, 클라우드 업체가 유지보수를 담당하는 서비스)
        - = 간단히, 처리율 제한을 지원하는 미들웨어
- 고려할 점
    - 현재 사용하는 프로그래밍 언어가 서버 측 구현을 지원하기에 효율이 충분히 높은가?
    - 처리율 제한 서비스를 구현하기에 충분한 인력이 있는가?

### **처리율 제한 알고리즘**

- **토큰 버킷 알고리즘**
    - 보편적으로 사용 (아마존, 스트라이프 등)
    - 보통 API endpoint마다 별도의 버킷을 둠
    
    알고리즘 동작 원리
    
    ![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/c572571b-8a19-4c28-929f-c23789a58601/99c3c9b3-93df-4471-87af-08481211ab31/Untitled.png)
    
    - 토큰 버킷 (용량을 갖는 컨테이너)에 토큰 공급기(refiler)가 토큰 추가.
    - 버킷이 가득 차면 추가로 공급된 토큰은 버려짐(overflow)
    - 요청이 왔을때, 버킷에 충분한 토큰이 있을 경우 요청을 시스템에 전달하고, 아니면 요청을 버림
    
    장점
    
    - 쉬운 구현
    - 효율적인 메모리 사용
    - 짧은 시간에 집중되는 트래픽(burst of traffic)처리 가능
    
    단점
    
    - parameter tuning 이 까다로움 (버킷 크기, 토큰 공급률)
        - 버킷 크기 : 버킷에 담을 수 있는 토큰의 최대 개수
        - 토큰 공급률(refill rate ) : 초당 몇 개의 토큰이 버킷에 공급되는가

- **누출 버킷 알고리즘**
    - 토큰 버킷 알고리즘과의 차이점 : 이 알고리즘은 요청 처리율이 고정되어 있음
    - shopify 전자상거래 기업이 이 알고리즘 사용 중
    
    알고리즘 동작 원리
    
    - FIFO queue로 구현
    - 요청이 도착하면 큐에 추가 (큐가 가득 차있으면 요청 버림)
    - **지정된 시간마다** 큐에서 요청을 꺼내어 처리함
    
    장점
    
    - 메모리 사용량 측면에서 효율적 (큐의 크기가 제한되어 있어서)
    - stable outflow rate가 필요한 서비스에 적합 (고정된 처리율을 갖고 있어서)
    
    단점
    
    - 단시간에 많은 트래픽이 몰리는 경우에는 부적절함 (요청들이 버려질 가능성)
    - parameter tuning 이 까다로울 수 있음 (버킷 크기, 처리율)
        - 버킷 크기 : 큐 사이즈
        - 처리율(outflow rate) : 지정된 시간당 몇 개의 항목을 처리할지 지정하는 값 (단위:sec)

- **고정 윈도 카운터 알고리즘**
    
    알고리즘
    
    - timeline을 window로 나누고, 각 window마다 counter를 붙임
    - 요청이 접수될때마다 counter +1
    - counter값이 threshold에 도달하면 새 window를 열게됌 (새 window열릴때까지 새로운 요청은 버려짐)
    
    장점
    
    - 메모리 효율이 좋음
    - window가 닫히는 시점에 counter를 초기화하는 방식은 트래픽 패턴을 처리하기에 적합함
    
    단점
    
    ![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/c572571b-8a19-4c28-929f-c23789a58601/a450c3b9-740b-4579-8f64-2eaf3d0b61c7/Untitled.png)
    
    - window 경계 부근에 순간적으로 많은 트래픽이 집중될 경우, window에 할당된 양보다 더 많은 요청이 처리될 수 있음

- **이동 윈도 로깅 알고리즘**
    
    ![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/c572571b-8a19-4c28-929f-c23789a58601/21e28fbb-3201-4470-b2be-28979157c8c4/Untitled.png)
    
    - 고정 윈도 카운터 알고리즘의 단점 해결
    
    알고리즘
    
    - 요청의 timestamp 추적
        - timestamp data는 보통 Redis의 sorted set 같은 캐시에 저장함
    - 새 요청이 오면, 현재 window의 시작 지점보다 오래된 timestamp 제거
    - 새 요청의 timestamp를 log에 추가
    - log의 크기가 허용치보다 같거나 작으면 요청을 시스템에 전달 (아니면 처리 거부)
    
    장점
    
    - 어떤 window를 보더라도 허용되는 요청의 개수가 시스템의 처리율 한도를 넘지 않음
    
    단점
    
    - 다량의 메모리 사용 (거부된 요청의 타임스탬프도 보관해서)

- **이동 윈도 카운터 알고리즘**
    
    ![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/c572571b-8a19-4c28-929f-c23789a58601/84ff3314-e04c-4f84-b03f-1137999d95f7/Untitled.png)
    
    - 고정 윈도 카운터 알고리즘 + 이동 윈도 로깅 알고리즘
    
    알고리즘
    
    - 그림
        - 현재 window에 몇 개의 요청이 온 것일까?
            - 현재 1분간의 요청 수 + 직전 1분간의 요청 수 * 이동 윈도와 직전 1분이 겹치는 비율  = 3+5*70% = 6.5 → 반내림해서 6개
    
    장점
    
    - 메모리 효율이 좋음
    - 짧은 시간에 몰리는 트래픽에 잘 대응함 (이전 시간대의 평균 처리율에 따라 현재 윈도의 상태를 계산해서)
    
    단점
    
    - 직전 시간대에 도착한 요청이 균등하게 분포되어 있다고 가정하고 추정치를 계산해서 다소 느슨함

### **개략적인 아키텍처**

- 처리율 제한 알고리즘
    
    ![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/c572571b-8a19-4c28-929f-c23789a58601/1d6cd579-05ab-455b-86a2-865d1f09ac44/Untitled.png)
    
    - 얼마나 많은 요청이 접수되었는지 추적할 수 있는 카운터를 추적 대상별로 두고, 카운터값이 threshold를 넘은 이후에 도착한 요청은 거부
    - 추적 대상 예시 : 사용자, IP주소, API 엔드포인트
    - 카운터는 어디에 보관할 것인가?
        - Redis
            - 처리율 제한 장치를 구현할 때 자주 사용되는 메모리 기반 저장장치
            - INCR, EXPIRE 명령어 지원함
                - INCR : 메모리에 저장된 카운터의 값을 1만큼 증가시킴
                - EXPIRE : 카운터에 타임아웃 값 설정. 설정된 시간이 지나면 카운터는 자동 삭제됌

## 3. 상세 설계

**처리율 제한 규칙은 어떻게 만들어지고 어디에 저장되는가?**

- Lyft 라는 기업은 처리율 제한에 오픈소스를 사용함.
- 식 → 보통 이런 규칙들은 configuration file 형태로 디스크에 저장됌

**처리가 제한된 요청들은 어떻게 처리되는가? (처리율 한도 초과 트래픽 처리)**

- 한도 제한에 걸린 message를 나중에 처리하기 위해 큐에 보관하는 경우도 있음
- 처리율 제한 장치는 HTTP header를 client에게 보냄
    - X-Ratelimit-Remaining : window 내에 남은 처리 가능 요청의 수
    - X-Ratelimit-Limit : 매 window마다 client가 전송할 수 있는 요청의 수
    - X-Ratelimit-Retry-After : 한도 제한에 걸리지 않으려면 몇 초 뒤에 요청을 다시 보내야 하는지 알림

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/c572571b-8a19-4c28-929f-c23789a58601/6b365df6-be35-4d98-8a27-e3d0c271ecba/Untitled.png)

1. 처리율 제한 규칙 디스크에 보관
2. 클라이언트 요청 → 처리율 제한 middleware에 전달
3. 처리율 제한 middleware는 제한 규칙을 캐시에서 가져옴 & 카운터, 마지막 요청의 timestamp를 Redis cache에서 가져옴 
4. middleware → 해당 요청이 처리율 제한에 걸리지 않은 경우, API서버로 전송 / 해당 요청이 처리율 제한에 걸린 경우 429 HTTP 에러를 클라이언트에게 보냄 

**분산 환경에서의 처리율 제한 장치 구현**

- 문제 1. race condition
    
    ![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/c572571b-8a19-4c28-929f-c23789a58601/58aee1c2-87f3-4551-b26e-16d7dc306990/Untitled.png)
    
    - Redis에서 counter 값을 읽음
    - counter+1 값이 threshold를 넘지 않으면 Redis에 보관된 counter값 +1
    - ~~해결 방법 : lock~~
        - 시스템의 성능을 떨어뜨림.
    - 해결 방법 : Lua script
    - 해결 방법 : Redis 자료구조(sorted set) 사용
- 문제 2. synchronization
    
    ![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/c572571b-8a19-4c28-929f-c23789a58601/358fd21e-dbe0-4702-abee-e8aeb563594c/Untitled.png)
    
    - 웹 계층은 stateless이므로 오른쪽 그림처럼 각기 다른 제한 장치로 요청을 보낼 수 있음
    - 동기화를 하지 않으면 제한 장치 1은 client2에 대해 아무것도 모르므로 처리율 제한을 올바르게 수행할 수 없음
    - 처리율 제한 장치 서버를 여러 대 두면 동기화가 필요해짐.
    - 해결 방법 : ~~sticky session을 활용하여 같은 클라이언트로부터의 요청은 항상 같은 처리율 제한 장치로 보냄~~ → 규모 확장 x, 유연x
    - 해결 방법 : Redis 같은 중앙 집중형 데이터 저장소 사용
        
        ![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/c572571b-8a19-4c28-929f-c23789a58601/b7392755-79f8-469a-9f67-bf7617b49a67/Untitled.png)
        

**성능 최적화**

- 데이터센터에서 멀리 떨어진 사용자를 지원 → latency 증가
    - 해결 : 사용자의 트래픽을 가장 가까운 edge server로 전달하여 지연 시간 줄임
- 제한 장치 간에 데이터를 동기화할 때 최종 일관성 모델(eventual consistency model) 사용

**모니터링**

- 목적
    - 채택된 처리율 제한 알고리즘이 효과적인지 확인
        - 깜짝 세일로 트래픽이 급증하는 상황 → 토큰 버킷이 적합함
    - 정의한 처리율 제한 규칙이 효과적인지 확인
        - 규칙이 너무 빡빡하게 설정되어 유효 요청이 많이 버려지진 않는지

## 4.마무리

시간이 남으면 추가로 고려해 볼 내용

- hard / soft 처리율 제한
    - hard : 요청의 개수는 임계치를 절대 넘어설 수 없다
    - soft : 요청 개수는 잠시동안은 임계치를 넘어설 수 있다
- 다양한 계층(네트워크 계층)에서의 처리율 제한
    - 앞선 예시는 application 계층에서 처리율 제한을 하는 예시였음
- 처리율 제한을 회피하는 방법, 클라이언트를 어떻게 설계하는 것이 최선인가?
