### 1단계 : 문제 이해 및 설계 범위 확정

**요구사항**

```
- 빠른 응답 속도 : 사용자가 검색어를 입력함에 따라 자동완성 검색어도 충분히 빠르게 표시되어야 한다. 페이스북의 경우 응답속도를 100 밀리초 이내라고 규정한다. 그렇지 않으면 시스템 이용이 불편해진다.
- 연관성 : 검색어는 사용자가 입력한 단어와 연관성이 있어야 한다.
- 정렬 : 시스템의 계산 결과는 인기도 등의 순위 모델에 의해 정렬되어야 한다.
- 규모 확장성 : 시스템은 많은 트래픽을 감당할 수 있도록 확장 가능해야 한다.
- 고가용성 : 시스템의 일부에 장애가 발생하거나 느려지거나, 예상치 못한 네트워크 문제가 발생해도 시스템은 계속 사용 가능해야 한다.
```

**개략적 규모 추정**

- DAU는 천만명, 평균적으로 한 사용자는 매일 10건의 검색을 수행
- 질의 할 때 평균적으로 20바이트의 데이터를 입력
    - 문자 인코딩 방법은 ASCII를 사용한다고 가정하면 1문자 = 1바이트
    - 질의당 평균 1단어 5글자 x 4개단어 = 20 바이트
- 글자를 입력할 때마다 서버로 요청을 보내므로 평균적으로 1회 검색당 20건의 요청이 백엔드로 전달

```
# dinner 검색 시

search?q=d
search?q=di
search?q=din
search?q=dinn
search?q=dinne
```

- 대략 초당 24,000건의 QPS 발생 = (10,000,000 x 10 질의 / 일 x 20자 / 24시간 / 3600초)
- 질의 가운데 20% 정도는 신규 검색어 = 매일 0.4GB의 신규 데이터가 시스템에 추가 (10,000,000 x 10 질의 / 일 x 20자 x 20%)

### 2단계 : 개략적인 설계안 제시 및 동의 구하기

시스템을 두 부분으로 나눌 수 있음

- 데이터 수집 서비스: 입력한 질의 수집하는 서비스
- 질의 서비스: 질의에 5개의 인기 검색어를 정렬해 반환하는 서비스

**데이터 수집 서비스**

질의가 들어올 때마다 키-값 스토어에 질의와 빈도를 저장하는 빈도 테이블을 생성

!https://user-images.githubusercontent.com/75432228/239871595-e6196950-3005-4b19-950d-4b5acdf811c7.png

**질의 서비스**

```
SELECT * FROM frequence_table WHERE query LIKE 'prefix%' ORDER BY frequency DESC LIMIT 5;
```

- 검색어와 검색어의 빈도를 저장하는 테이블이 만들어져 있다면 빈도가 가장 높은 5개의 단어가 자동완성으로 제공
- 데이터가 많아지면 병목 현상이 생길 수 있다.

### 3단계 : 상세 설계

**트라이 자료구조**

트라이는 문자열을 찾기 위해 사용되는 자료구조 중 하나

- 트라이는 트리 형태다.
- 루트 노드는 빈 문자열을 나타낸다.
- 각 노드는 글자 하나를 저장한다.
- 자식 노드로, 해당 글자 다음에 등장할 모든 글자를 저장하는 노드를 가질 수 있다. (26개의 노드)
- 각 트리 노드는 하나의 단어, 또는 접두어의 문자열을 나타낸다.

!https://user-images.githubusercontent.com/75432228/239872803-c500f0d3-15a7-4421-9906-4464feb387d6.png

가장 많이 사용된 질의어 k개는 어떻게 찾아낼 수 있는가?

1. 해당 접두어를 표현하는 노드를 찾는다. → O(p)
2. 해당 노드부터 시작하는 하위 트리를 탐색하여, 모든 유효 노드를 찾는다. (유효한 검색 문자열을 구성하는 노드가 유효 노드다.) → O(c)
3. 유효 노드를 정렬하여 가장 인기있는 검색어 k개를 찾는다. →O(c log c)
4. 유효노드를 정렬해 가장 인기 있는 검색어를 찾는다.

총 시간 복잡도는 O(p) + O(c) + O(c log c) = O(c log c)

!https://user-images.githubusercontent.com/75432228/239873316-e959b40e-3968-4fd0-a6f8-97364d76d17b.png

최악의 경우 k개를 얻기 위해 모든 트리를 다 검색해야 하므로 다음 두 방법을 통해 시간복잡도를 O(1)로 수렴시킬 수 있다. 

- **접두어의 최대 길이 제한**
    - 사용자가 검색창에 긴 검색어를 입력하는 경우는 거의 없으므로 p값의 최대 길이를 제한
    - 이러면 위 1단계의 시간 복잡도는 O(1)
- **노드에 인기 검색어 캐시**
    - 각 노드에 k개의 인기 검색어를 저장해두면 트라이를 전체 검색하는 일을 방지 가능
    - 각 노드에 k개의 인기 검색어를 저장해두면 트라이를 전체 검색하는 일을 방지 가능
    - but 저장 공간을 많이 쓰기 때문에 응답속도가 중요한 경우 속도 > 저장 공간 트레이드오프 고려

이제 시간 복잡도는 O(1) + O(1) + O(1) = O(1)

**데이터 수집 서비스**

- 수천만건의 데이터를 매일 수집될 때, 그때마다 트라이를 갱신하면 질의 서비스가 심각하게 느려질 것이다.
- 일단 트라이가 만들어지고 나면 인기 검색어는 그다지 자주 바뀌지 않을 것이다. 따라서 너무 자주 갱신할 필요는 없다.
- 트라이를 만드는데 사용하는 데이터는 보통 데이터 분석 서비스/로깅 서비스로 부터 온다.

!https://user-images.githubusercontent.com/75432228/239874914-7c1a73f7-2445-47b0-b496-4bdec6206b4a.png

- Analytics logs: 입력된 질의에 관한 원본 데이터
- Aggregators: Log 취합 및 전처리, DB 저장
- Workers: 비동기적으로 트라이 자료구조 생성 및 저장
- Trie cache: 데이터 메모리에 유지시켜 읽기 연산 성능 높임 → 주기적으로 DB 스냅샷
- Trie DB
    - Document store
    - Key-value store

**질의 서비스**

!https://user-images.githubusercontent.com/75432228/239878167-d21c3317-3b54-44ba-a723-8ec7ef7f0822.png

질의 서비스는 빨라야한다

- 서버 앞 단에서 로드밸런서로 부터 요청을 받음
- 서버로 요청이 들어오면 트라이 캐시에서 데이터 가져옴
- 캐시에 없으면 데이터베이스 조회해 캐시를 채움. 이후 캐시에서 가져옴.

더 생각해봐야하는 최적화 방안

- ajax 요청
    - 클라이언트의 페이지 새로고침 없이 요청 가능
- 브라우저 캐싱
- 데이터 샘플링
    - 모든 질의를 다 로깅? 자원부족할 수 있다.
    - N개 요청 중 1개만 로깅

**트라이 연산**

**저장소 규모 확장**

| 방법 | 설명 |
| --- | --- |
| 첫 글자 기준으로 샤딩 | 영어만 지원하면 되기 때문에 첫 글자를 기준으로 샤딩 가능사용 가능한 서버가 최대 26대로 제한 |
| 두 번째 글자까지 묶어서 샤딩 | 위 문제를 해결하기 위해서는 계층적으로 샤딩but 데이터가 서버에 균등하게 배분되지 않는다ex. “aa” 부터 “ag” 까지는 첫 번째 서버, “ah” - “an” 은 두 번째 서버 |
| 샤드 맵 매니저로 매핑될 노드 지정 | 샤드 맵 매니저가 데이터가 균등하게 배분되도록, 어떤 검색어가 어디로 들어갈지 결정해준다.ex. “u”, “v”, “w” 로 시작하는 노드의 합이, “s” 로 시작하는 노드 하나와 비슷하다면, 각각 두개의 노드로 샤딩 |
|  |  |

### 4단계 : 마무리

- 다국어 지원이 가능한 시스템 : 트라이에 유니코드 데이터를 저장
- 국가별로 인기 검색어 순위가 다르다면 : 국가별로 다른 트라이를 사용, 트라이를 CDN에 저장하여 국가별로 응답속도를 높임
- 실시간으로 변하는 검색어 추이 반영
    - 현재의 배치 작업, 트라이는 부적절
    - 샤딩을 통하여 작업 대상 데이터의 양을 줄이고 순위 모델을 바꿔 최근 검색어에 더 높은 가중치를 준다.
    - 스트림 형태의 데이터 처리하기 위해서 `하둡 맵 리듀스`, `아파치 스파크 스트리밍`,`아파치 카프카` 등 고려
